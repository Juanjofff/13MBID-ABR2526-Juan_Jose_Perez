{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5b75f6",
   "metadata": {},
   "source": [
    "## Máster en Big Data y Data Science\n",
    "\n",
    "### Metodologías de gestión y diseño de proyectos de big data\n",
    "\n",
    "#### AP2 - Modelado y evaluación\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta se realiza la experimentación para generación del modelo de predicción objetivo del proyecto y la evaluación del mismo.\n",
    "La versión del dataset a utilizar es la obtenida a partir de las operaciones de transformación.\n",
    "\n",
    "---\n",
    "\n",
    "En esta versión de la libreta se va a incorporta el registro de los detalles de la experimentación con la librería MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98487f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerías necesarias y se suprimen las advertencias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f9174",
   "metadata": {},
   "source": [
    "Se agrega la librería mlflow y se configura inicialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39062de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///Users/juanjo/Documents/Maestría/13 Metodología de Gestión y '\n",
       " 'Diseño de Big '\n",
       " 'Data/RepoGithub/13MBID-ABR2526-Juan_Jose_Perez/notebooks/../mlruns/156006986107326267'), creation_time=1772289281220, experiment_id='156006986107326267', last_update_time=1772289281220, lifecycle_stage='active', name='Proyecto 13MBID-ABR2526 - Experimentación Original', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de MLFlow\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "mlflow.set_experiment(\"Proyecto 13MBID-ABR2526 - Experimentación Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d8e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education housing loan    contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no   no  telephone   may   \n",
       "1   57   services  married  high.school      no   no  telephone   may   \n",
       "2   37   services  married  high.school     yes   no  telephone   may   \n",
       "3   40     admin.  married     basic.6y      no   no  telephone   may   \n",
       "4   56   services  married  high.school      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week  duration  campaign  pdays  previous     poutcome  emp_var_rate  \\\n",
       "0         mon       261         1    999         0  nonexistent           1.1   \n",
       "1         mon       149         1    999         0  nonexistent           1.1   \n",
       "2         mon       226         1    999         0  nonexistent           1.1   \n",
       "3         mon       151         1    999         0  nonexistent           1.1   \n",
       "4         mon       307         1    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de los datos\n",
    "df = pd.read_csv('../data/processed/bank-processed.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1a6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide el dataset en variables predictoras y variable objetivo\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be62f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el conjunto de entrenamiento y prueba con estratificación\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1ce41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n",
       "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month',\n",
       "       'day_of_week', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se separan las columnas numéricas\n",
    "numerical_columns=X_train.select_dtypes(exclude='object').columns\n",
    "display(numerical_columns)\n",
    "\n",
    "categorical_columns=X_train.select_dtypes(include='object').columns\n",
    "display(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e4f9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    27179\n",
       "1     3406\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica la distribución de la variable objetivo en el conjunto de entrenamiento\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un pipeline para preprocesamiento de datos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler  \n",
    "\n",
    "# Pipeline para valores numéricos\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para valores categóricos\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('OneHotEncoder', OneHotEncoder(drop='first',sparse_output=False))\n",
    "])\n",
    "\n",
    "# Se configuran los preprocesadores\n",
    "preprocessor_full = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', cat_pipeline, categorical_columns)\n",
    "]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1bb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_train_valid = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', cat_pipeline, categorical_columns)\n",
    "]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47621435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ajusta y transforma el conjunto de entrenamiento y prueba\n",
    "x_train_prep = preprocessor_full.fit_transform(X_train)\n",
    "x_test_prep = preprocessor_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d46c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: 30585\n",
      "Tamaño balanceado: 5438\n",
      "Distribución balanceada: target\n",
      "0.0    2719\n",
      "1.0    2719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Se aplica submuestreo a los datos preprocesados\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Combinar los datos preprocesados con las etiquetas\n",
    "train_data = x_train_prep.copy()\n",
    "train_data['target'] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Separar por clase\n",
    "class_0 = train_data[train_data['target'] == 0]\n",
    "class_1 = train_data[train_data['target'] == 1]\n",
    "\n",
    "# Encontrar la clase minoritaria\n",
    "min_count = min(len(class_0), len(class_1))\n",
    "\n",
    "# Submuestreo balanceado - tomar una muestra igual al tamaño de la clase minoritaria\n",
    "class_0_balanced = resample(class_0, n_samples=min_count, random_state=42)\n",
    "class_1_balanced = resample(class_1, n_samples=min_count, random_state=42)\n",
    "\n",
    "# Combinar las clases balanceadas\n",
    "balanced_data = pd.concat([class_0_balanced, class_1_balanced])\n",
    "\n",
    "# Separar características y objetivo\n",
    "x_train_resampled = balanced_data.drop('target', axis=1)\n",
    "y_train_resampled = balanced_data['target']\n",
    "\n",
    "print(f\"Tamaño original: {len(x_train_prep)}\")\n",
    "print(f\"Tamaño balanceado: {len(x_train_resampled)}\")\n",
    "print(f\"Distribución balanceada: {y_train_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2f40e",
   "metadata": {},
   "source": [
    "ESTA APARTADO SE VA A CAMBIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4767dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Se genera una función para realizar validación cruzada\n",
    "def cross_val(model):\n",
    "    scores = cross_val_score(model,x_train_resampled , y_train_resampled, cv=5, scoring='f1')\n",
    "    print('cross validation f1 scores',scores*100)\n",
    "    print('cross validation f1 mean',scores.mean()*100)\n",
    "    print('cross validation f1 std',scores.std())\n",
    "    print('-'*50)\n",
    "    scores = cross_val_score(model,x_train_resampled , y_train_resampled, cv=5, scoring='recall')\n",
    "    print('cross validation recall scores',scores*100)\n",
    "    print('cross validation recall mean',scores.mean()*100)\n",
    "    print('cross validation recall std',scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30b384",
   "metadata": {},
   "source": [
    "---\n",
    "El cambio consuste en que la función directamente registre los detalle de la experimentación en mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f4927c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.spawn import import_main_path\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "def cross_val_mlflow(model, model_name, params=None):\n",
    "    \"\"\"\n",
    "    Realiza la validación cruzada de un modelo y registra los resultados en MLFlow\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a validar\n",
    "        model_name: Nombre del modelo\n",
    "        params: Parámetros del modelo\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        f1_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='f1')\n",
    "        f1_mean = f1_scores.mean()\n",
    "        f1_std = f1_scores.std()\n",
    "        \n",
    "        recall_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='recall')\n",
    "        recall_mean = recall_scores.mean()\n",
    "        recall_std = recall_scores.std()\n",
    "\n",
    "        precision_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='precision')\n",
    "        precision_mean = precision_scores.mean()\n",
    "        precision_std = precision_scores.std()\n",
    "\n",
    "        accuracy_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "        accuracy_mean = accuracy_scores.mean()\n",
    "        accuracy_std = accuracy_scores.std()\n",
    "\n",
    "        #Entrenar al modelo\n",
    "        model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "        # hacemos predicciones\n",
    "        y_pred = model.predict(x_test_prep)\n",
    "\n",
    "        # Obtenemos model signature\n",
    "        signature = infer_signature(x_train_resampled, y_pred)\n",
    "\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        test_recall = recall_score(y_test, y_pred)\n",
    "        test_precision = precision_score(y_test, y_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Registramos los parametros y metricas en MLFlow\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        else:\n",
    "            mlflow.log_params(model.get_params())\n",
    "        \n",
    "        mlflow.log_params({\n",
    "            \"train_samples\": len(x_train_resampled),\n",
    "            \"test_samples\": len(x_test_prep),\n",
    "            \"balancing_method\": \"undersampling\",\n",
    "            \"cv_folds\": 5\n",
    "        })\n",
    "\n",
    "        # Registramos las metricas de la validación cruzada\n",
    "        mlflow.log_metrics({\n",
    "            \"cv_f1_mean\": f1_mean,\n",
    "            \"cv_f1_std\": f1_std,\n",
    "            \"cv_recall_mean\": recall_mean,\n",
    "            \"cv_recall_std\": recall_std,\n",
    "            \"cv_precision_mean\": precision_mean,\n",
    "            \"cv_precision_std\": precision_std,\n",
    "            \"cv_accuracy_mean\": accuracy_mean,\n",
    "            \"cv_accuracy_std\": accuracy_std\n",
    "        })\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        })\n",
    "\n",
    "        # Registramos el modelo\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            artifact_path=\"model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "        print(f\"Modelo {model_name} registrado en MLFlow con el id de ejecución {mlflow.active_run().info.run_id}\")\n",
    "\n",
    "        return model, {\n",
    "            \"cv_f1_mean\": f1_mean,\n",
    "            \"cv_recall_mean\": recall_mean,\n",
    "            \"cv_precision_mean\": precision_mean,\n",
    "            \"cv_accuracy_mean\": accuracy_mean,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3b776",
   "metadata": {},
   "source": [
    "Se cambias estas celdas por una que hace todas las llamadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica un modelo de regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1,penalty='l2',solver='liblinear',random_state=1,max_iter=100,tol=0.000000001)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(max_iter=10000,tol=0.001)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knclassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier()\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree plot\n",
    "from sklearn.tree import plot_tree\n",
    "tree.fit(x_train_prep, y_train)\n",
    "plot_tree(tree, filled=True, rounded=True,max_depth=2,fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c90f4eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6336  460]\n",
      " [ 386  465]]\n"
     ]
    }
   ],
   "source": [
    "# Se obtiene la matriz de confusión para el modelo\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = tree.predict(x_test_prep)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b60a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza la matriz de confusión\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no', 'yes'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448275c0",
   "metadata": {},
   "source": [
    "-----\n",
    "Esta es la nueva celda que hace la invocación al proceso con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89dbcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/28 10:13:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Logistic Regression registrado en MLFlow con el id de ejecución 01dd288bbc5b4f96bc9551ce539fb519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/28 10:13:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Support Vector Machine registrado en MLFlow con el id de ejecución c42897b6fe254e6b9948ff1633451606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/28 10:13:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo K-Nearest Neighbors registrado en MLFlow con el id de ejecución b552b1d053e34988abd77df5e4c4d5d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/28 10:13:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Decision Tree Classifier registrado en MLFlow con el id de ejecución 38a6100520344ae79f171bd688a60dbe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Resultados \n",
    "resultados = {}\n",
    "\n",
    "# Método 1: Regresión \n",
    "lr = LogisticRegression(C=1,penalty='l2',solver='liblinear',random_state=1,max_iter=100,tol=0.000000001)\n",
    "model_lr, resultados_lr = cross_val_mlflow(lr, \"Logistic Regression\")\n",
    "resultados[\"Logistic Regression\"] = resultados_lr\n",
    "\n",
    "# Método 2: SVC\n",
    "svc = LinearSVC(max_iter=10000,tol=0.001)\n",
    "model_svc, resultados_svc = cross_val_mlflow(svc, \"Support Vector Machine\")\n",
    "resultados[\"Support Vector Machine\"] = resultados_svc\n",
    "\n",
    "\n",
    "# Método 3: KNN\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "model_knc, resultados_knc = cross_val_mlflow(knc, \"K-Nearest Neighbors\")\n",
    "resultados[\"K-Nearest Neighbors\"] = resultados_knc\n",
    "\n",
    "# Método 4: Árbol de decisión\n",
    "tree = DecisionTreeClassifier()\n",
    "model_tree, resultados_tree = cross_val_mlflow(tree, \"Decision Tree Classifier\")\n",
    "resultados[\"Decision Tree Classifier\"] = resultados_tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a1dfb",
   "metadata": {},
   "source": [
    "Se realiza una comparación de los modelos para seleccionar el que va a ser utilizado posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2665e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          cv_f1_mean  cv_recall_mean  cv_precision_mean  \\\n",
      "Decision Tree Classifier      0.6958          0.7381             0.6589   \n",
      "K-Nearest Neighbors           0.5699          0.5815             0.5591   \n",
      "Logistic Regression           0.5244          0.5204             0.5289   \n",
      "Support Vector Machine        0.5241          0.5208             0.5279   \n",
      "\n",
      "                          cv_accuracy_mean  test_f1  test_recall  \\\n",
      "Decision Tree Classifier            0.6804   0.1788       0.4113   \n",
      "K-Nearest Neighbors                 0.5612   0.1551       0.3960   \n",
      "Logistic Regression                 0.5278   0.1100       0.2656   \n",
      "Support Vector Machine              0.5268   0.1080       0.2573   \n",
      "\n",
      "                          test_precision  test_accuracy  \n",
      "Decision Tree Classifier          0.1142         0.5794  \n",
      "K-Nearest Neighbors               0.0965         0.5199  \n",
      "Logistic Regression               0.0693         0.5216  \n",
      "Support Vector Machine            0.0683         0.5269  \n",
      "\n",
      "El mejor modelo basado en el conjunto de prueba es:  Decision Tree Classifier\n",
      "Valor de F1 en test: 0.1788\n",
      "Valor de recall en test: 0.4113\n"
     ]
    }
   ],
   "source": [
    "df_comparacion = pd.DataFrame(resultados).T\n",
    "df_comparacion = df_comparacion.round(4)\n",
    "df_comparacion = df_comparacion.sort_values(by='test_f1', ascending=False)\n",
    "\n",
    "print(df_comparacion)\n",
    "\n",
    "print(\"\\nEl mejor modelo basado en el conjunto de prueba es: \", df_comparacion.index[0])\n",
    "print(f\"Valor de F1 en test: {df_comparacion.loc[df_comparacion.index[0], 'test_f1']}\")\n",
    "print(f\"Valor de recall en test: {df_comparacion.loc[df_comparacion.index[0], 'test_recall']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bdc3a",
   "metadata": {},
   "source": [
    "#### Predicción con datos nuevos (sin clasificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9289542f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "      <th>contacted_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education housing loan    contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no   no  telephone   may   \n",
       "1   57   services  married  high.school      no   no  telephone   may   \n",
       "2   37   services  married  high.school     yes   no  telephone   may   \n",
       "3   40     admin.  married     basic.6y      no   no  telephone   may   \n",
       "4   56   services  married  high.school      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week  duration  campaign  previous     poutcome  emp_var_rate  \\\n",
       "0         mon       261         1         0  nonexistent           1.1   \n",
       "1         mon       149         1         0  nonexistent           1.1   \n",
       "2         mon       226         1         0  nonexistent           1.1   \n",
       "3         mon       151         1         0  nonexistent           1.1   \n",
       "4         mon       307         1         0  nonexistent           1.1   \n",
       "\n",
       "   cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  contacted_before  \n",
       "0          93.994          -36.4      4.857       5191.0  no               NaN  \n",
       "1          93.994          -36.4      4.857       5191.0  no               NaN  \n",
       "2          93.994          -36.4      4.857       5191.0  no               NaN  \n",
       "3          93.994          -36.4      4.857       5191.0  no               NaN  \n",
       "4          93.994          -36.4      4.857       5191.0  no               NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nuevos = pd.read_csv('../data/raw/bank-additional-new.csv')\n",
    "df_nuevos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6746b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del conjunto de datos nuevos:\n",
      "Forma: (9, 20)\n",
      "\n",
      "Tipos de datos:\n",
      "age                   int64\n",
      "job                  object\n",
      "marital              object\n",
      "education            object\n",
      "housing              object\n",
      "loan                 object\n",
      "contact              object\n",
      "month                object\n",
      "day_of_week          object\n",
      "duration              int64\n",
      "campaign              int64\n",
      "previous              int64\n",
      "poutcome             object\n",
      "emp_var_rate        float64\n",
      "cons_price_idx      float64\n",
      "cons_conf_idx       float64\n",
      "euribor3m           float64\n",
      "nr_employed         float64\n",
      "y                    object\n",
      "contacted_before    float64\n",
      "dtype: object\n",
      "\n",
      "Valores nulos:\n",
      "age                 0\n",
      "job                 0\n",
      "marital             0\n",
      "education           0\n",
      "housing             0\n",
      "loan                0\n",
      "contact             0\n",
      "month               0\n",
      "day_of_week         0\n",
      "duration            0\n",
      "campaign            0\n",
      "previous            0\n",
      "poutcome            0\n",
      "emp_var_rate        0\n",
      "cons_price_idx      0\n",
      "cons_conf_idx       0\n",
      "euribor3m           0\n",
      "nr_employed         0\n",
      "y                   0\n",
      "contacted_before    9\n",
      "dtype: int64\n",
      "\n",
      "Columnas categóricas en nuevos datos:\n",
      "['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
      "\n",
      "Columnas numéricas en nuevos datos:\n",
      "['age', 'duration', 'campaign', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'contacted_before']\n"
     ]
    }
   ],
   "source": [
    "# Diagnosticar el problema con los nuevos datos\n",
    "print(\"Información del conjunto de datos nuevos:\")\n",
    "print(f\"Forma: {df_nuevos.shape}\")\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(df_nuevos.dtypes)\n",
    "print(\"\\nValores nulos:\")\n",
    "print(df_nuevos.isnull().sum())\n",
    "print(\"\\nColumnas categóricas en nuevos datos:\")\n",
    "print(df_nuevos.select_dtypes(include='object').columns.tolist())\n",
    "print(\"\\nColumnas numéricas en nuevos datos:\")\n",
    "print(df_nuevos.select_dtypes(exclude='object').columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae6597f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de columnas:\n",
      "Columnas en datos originales: ['age', 'job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
      "Columnas en datos nuevos: ['age', 'job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y', 'contacted_before']\n",
      "\n",
      "Columnas que están en nuevos pero no en originales:\n",
      "{'y', 'contacted_before'}\n",
      "\n",
      "Columnas que están en originales pero no en nuevos:\n",
      "{'pdays'}\n"
     ]
    }
   ],
   "source": [
    "# Comparar con los datos de entrenamiento originales\n",
    "print(\"Comparación de columnas:\")\n",
    "print(f\"Columnas en datos originales: {list(X.columns)}\")\n",
    "print(f\"Columnas en datos nuevos: {list(df_nuevos.columns)}\")\n",
    "\n",
    "print(\"\\nColumnas que están en nuevos pero no en originales:\")\n",
    "new_cols = set(df_nuevos.columns) - set(X.columns)\n",
    "print(new_cols)\n",
    "\n",
    "print(\"\\nColumnas que están en originales pero no en nuevos:\")\n",
    "missing_cols = set(X.columns) - set(df_nuevos.columns)\n",
    "print(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5973eb61",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['pdays'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m X_new = df_nuevos.drop(\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_nuevos.columns \u001b[38;5;28;01melse\u001b[39;00m df_nuevos.copy()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Asegurar que las columnas estén en el mismo orden que en el entrenamiento\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_new = \u001b[43mX_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Manejar la columna contacted_before para que coincida con el formato de entrenamiento\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# En entrenamiento: 'no', 'yes' (string)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# En nuevos datos: NaN -> necesita convertirse a 'no' (asumiendo que NaN significa no contactado)\u001b[39;00m\n\u001b[32m     11\u001b[39m X_new[\u001b[33m'\u001b[39m\u001b[33mcontacted_before\u001b[39m\u001b[33m'\u001b[39m] = X_new[\u001b[33m'\u001b[39m\u001b[33mcontacted_before\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33mno\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Maestría/13 Metodología de Gestión y Diseño de Big Data/RepoGithub/13MBID-ABR2526-Juan_Jose_Perez/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Maestría/13 Metodología de Gestión y Diseño de Big Data/RepoGithub/13MBID-ABR2526-Juan_Jose_Perez/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Maestría/13 Metodología de Gestión y Diseño de Big Data/RepoGithub/13MBID-ABR2526-Juan_Jose_Perez/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['pdays'] not in index\""
     ]
    }
   ],
   "source": [
    "# Se hace la predicción con los nuevos datos\n",
    "# Primero, eliminar la columna objetivo si existe y preparar las características\n",
    "X_new = df_nuevos.drop('y', axis=1) if 'y' in df_nuevos.columns else df_nuevos.copy()\n",
    "\n",
    "# Asegurar que las columnas estén en el mismo orden que en el entrenamiento\n",
    "X_new = X_new[X.columns]\n",
    "\n",
    "# Manejar la columna contacted_before para que coincida con el formato de entrenamiento\n",
    "# En entrenamiento: 'no', 'yes' (string)\n",
    "# En nuevos datos: NaN -> necesita convertirse a 'no' (asumiendo que NaN significa no contactado)\n",
    "X_new['contacted_before'] = X_new['contacted_before'].fillna('no')\n",
    "\n",
    "# Convertir cualquier valor numérico a string si es necesario\n",
    "if X_new['contacted_before'].dtype in ['float64', 'int64']:\n",
    "    X_new['contacted_before'] = X_new['contacted_before'].map({0.0: 'no', 1.0: 'yes'}).fillna('no')\n",
    "\n",
    "# Asegurar que contacted_before sea de tipo object como en entrenamiento\n",
    "X_new['contacted_before'] = X_new['contacted_before'].astype('object')\n",
    "\n",
    "# Transformar los nuevos datos usando el mismo preprocesador y predecir\n",
    "try:\n",
    "    x_new_prep = preprocessor_full.transform(X_new)\n",
    "    \n",
    "    y_new_pred = tree.predict(x_new_prep)\n",
    "    print(f\"\\nPredicciones: {y_new_pred}\")\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Cliente': range(1, len(y_new_pred) + 1),\n",
    "        'Predicción_Numérica': y_new_pred,\n",
    "        'Suscribirá': ['No' if pred == 0 else 'Sí' for pred in y_new_pred]\n",
    "    })\n",
    "    print(\"\\nResultados detallados:\")\n",
    "    print(predictions_df.to_string(index=False))\n",
    "    \n",
    "    # Resumen de predicciones\n",
    "    pred_counts = pd.Series(y_new_pred).value_counts()\n",
    "    print(\"\\nResumen de predicciones:\")\n",
    "    for pred_val, count in pred_counts.items():\n",
    "        label = 'No realizará un depósito' if pred_val == 0 else 'Sí realizará un depósito'\n",
    "        print(f\"  {label}: {count} clientes ({count/len(y_new_pred)*100:.1f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error durante el preprocesamiento o predicción: {e}\")\n",
    "    print(\"Información adicional para depuración:\")\n",
    "    print(f\"Tipos de datos en X_new:\\n{X_new.dtypes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
